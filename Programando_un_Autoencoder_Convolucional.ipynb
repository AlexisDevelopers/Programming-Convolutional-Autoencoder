{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nPVq0ql7J5y6"
      },
      "source": [
        "# Programando un Autoencoder Convolucional\n",
        "\n",
        "\n",
        "<center><img src=\"https://www.researchgate.net/profile/Xifeng_Guo/publication/320658590/figure/fig1/AS:614154637418504@15234372844108/The-structure-of-proposed-Convolutional-AutoEncoders-CAE-for-MNIST-In-the-middle-there.png\" alt=\"Drawing\" width=\"600px\"/></center>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "85g9bd2oP03u"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import scipy as sc\n",
        "import sklearn as sk\n",
        "import pandas as pd\n",
        "import seaborn as sb\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from tensorflow.keras.utils      import to_categorical"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OuUvP_gpjwhm"
      },
      "outputs": [],
      "source": [
        "# Load the MNIST dataset.\n",
        "mnist = np.genfromtxt('./sample_data/mnist_train_small.csv', delimiter=',')\n",
        "\n",
        "# Separate the labels from the images\n",
        "X = mnist[:, 1:]\n",
        "Y = mnist[:, 0:1]\n",
        "\n",
        "# # Scale the data and One-Hot Encode the output.\n",
        "Xn = X / 255\n",
        "Yn = to_categorical(Y)\n",
        "\n",
        "# Use Sklearn's data splitter for train/test\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Train/test split partition to supervise overfitting.\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(Xn, Yn, test_size=0.3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6H8YBPxJPfdO",
        "outputId": "e99b3a3f-9c59-4132-de18-9b9cf3792d8a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(784,)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "X_train[0].shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras import *\n",
        "from tensorflow.keras.optimizers import *\n",
        "\n",
        "size = 28 # Image size.\n",
        "\n",
        "z = 10 # Size of the autoencoder's intermediate vector.\n",
        "\n",
        "# First we create the input for the encoder.\n",
        "inpE = Input(shape=(size, size, 1))  \n",
        "\n",
        "# Convolutional layers.\n",
        "encode_1 = Conv2D(filters=32, kernel_size=3, padding=\"same\", strides=2, activation='relu')(inpE)\n",
        "print(\"Conv1\", encode_1.shape)       \n",
        "encode_2 = Conv2D(filters=64, kernel_size=3, padding=\"same\", strides=2, activation='relu')(encode_1)  \n",
        "print(\"Conv2\", encode_2.shape)                            \n",
        "encode_3 = Conv2D(filters=128, kernel_size=3, strides=2, activation='relu')(encode_2)   \n",
        "print(\"Conv3\", encode_3.shape)                              \n",
        "encode_4 = Flatten()(encode_3) \n",
        "print(\"Flatten\", encode_4.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ODXT1G-0LG3w",
        "outputId": "61c89e00-37c9-43ba-aeaf-45bbce6620fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Conv1 (None, 14, 14, 32)\n",
            "Conv2 (None, 7, 7, 64)\n",
            "Conv3 (None, 3, 3, 128)\n",
            "Flatten (None, 1152)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lyu4Jam0P9EO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91544d91-c2bd-453d-d24e-a742620b4152"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DeConv3 (None, 7, 7, 64)\n",
            "DeConv2 (None, 14, 14, 32)\n",
            "DeConv1 (None, 28, 28, 1)\n"
          ]
        }
      ],
      "source": [
        "# The last layer of the encoder gives us the latent vector.\n",
        "c = Dense(z, activation=\"tanh\")(encode_4) \n",
        "\n",
        "# Create the input for the decoder\n",
        "inpD = Input(shape=(z))\n",
        "\n",
        "# Reshape\n",
        "FC = Dense(1152, activation=\"relu\")(inpD)\n",
        "decode = Reshape(target_shape=(3, 3, 128))(FC)\n",
        "\n",
        "# Reverse the encoder steps.\n",
        "decode_1 = Conv2DTranspose(filters=64, kernel_size=3,strides=2, activation='relu')(decode)\n",
        "print(\"DeConv3\", decode_1.shape)\n",
        "decode_2 = Conv2DTranspose(filters=32, kernel_size=3, padding=\"same\", strides=2, activation='relu')(decode_1)\n",
        "print(\"DeConv2\", decode_2.shape)\n",
        "decode_3 = Conv2DTranspose(filters=1, kernel_size=3, padding=\"same\", strides=2, activation='relu')(decode_2)\n",
        "print(\"DeConv1\", decode_3.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the encoder and decoder models\n",
        "encoder = Model(inputs=inpE, outputs=c)\n",
        "decoder = Model(inputs=inpD, outputs=decode_3)\n",
        "\n",
        "# Create the Autoencoder\n",
        "autoencoder = Sequential()\n",
        "autoencoder.add(encoder)\n",
        "autoencoder.add(decoder)\n",
        "\n",
        "# Compile and optimize.\n",
        "autoencoder.compile(optimizer=Adam(), loss='mse')"
      ],
      "metadata": {
        "id": "lbhpxee-SGym"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "autoencoder.fit(X_train.reshape(-1, size, size, 1), X_train.reshape(-1, size, size, 1), epochs=30, batch_size=128)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "20cW4Gh29Ki4",
        "outputId": "981aad0b-817c-4d36-9ce0-c100e47b84cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "110/110 [==============================] - 6s 8ms/step - loss: 0.0646\n",
            "Epoch 2/30\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.0326\n",
            "Epoch 3/30\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.0243\n",
            "Epoch 4/30\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.0209\n",
            "Epoch 5/30\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.0193\n",
            "Epoch 6/30\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.0182\n",
            "Epoch 7/30\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.0174\n",
            "Epoch 8/30\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.0167\n",
            "Epoch 9/30\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.0162\n",
            "Epoch 10/30\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.0158\n",
            "Epoch 11/30\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.0154\n",
            "Epoch 12/30\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.0151\n",
            "Epoch 13/30\n",
            "110/110 [==============================] - 1s 9ms/step - loss: 0.0147\n",
            "Epoch 14/30\n",
            "110/110 [==============================] - 1s 9ms/step - loss: 0.0144\n",
            "Epoch 15/30\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.0142\n",
            "Epoch 16/30\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.0139\n",
            "Epoch 17/30\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.0138\n",
            "Epoch 18/30\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.0136\n",
            "Epoch 19/30\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.0134\n",
            "Epoch 20/30\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.0132\n",
            "Epoch 21/30\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.0131\n",
            "Epoch 22/30\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.0130\n",
            "Epoch 23/30\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.0127\n",
            "Epoch 24/30\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.0126\n",
            "Epoch 25/30\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.0125\n",
            "Epoch 26/30\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.0124\n",
            "Epoch 27/30\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.0123\n",
            "Epoch 28/30\n",
            "110/110 [==============================] - 1s 9ms/step - loss: 0.0122\n",
            "Epoch 29/30\n",
            "110/110 [==============================] - 1s 9ms/step - loss: 0.0120\n",
            "Epoch 30/30\n",
            "110/110 [==============================] - 1s 9ms/step - loss: 0.0120\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fbb33e25a30>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axs = plt.subplots(1, 3, figsize=(10, 10))\n",
        "\n",
        "inpImg = X_test[np.random.randint(1, 100)].reshape(1, 28, 28, 1)\n",
        "\n",
        "# Input of the autoencoder.\n",
        "fig.axes[0].matshow(inpImg[0, :, :, 0])\n",
        "fig.axes[0].set_title(\"Input autoencoder\")\n",
        "fig.axes[0].axis(\"off\")\n",
        "\n",
        "# We call the autoencoder.\n",
        "outImg = autoencoder.predict(inpImg)\n",
        "\n",
        "# Get the latent vector.\n",
        "zVec = encoder.predict(inpImg)\n",
        "\n",
        "fig.axes[1].matshow(zVec)\n",
        "fig.axes[1].set_title(\"Latent vector\")\n",
        "fig.axes[1].axis(\"off\")\n",
        "\n",
        "#Output of the autoencoder.\n",
        "fig.axes[2].matshow(outImg[0, :, :, 0])\n",
        "fig.axes[2].set_title(\"Output autoencoder\")\n",
        "fig.axes[2].axis(\"off\")\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SbngyZbvGFAG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "outputId": "04c5a012-b031-43b2-9412-632a4e73ffeb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 208ms/step\n",
            "1/1 [==============================] - 0s 75ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x720 with 3 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}